#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <sensor_msgs/image_encodings.h>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <cv_bridge/cv_bridge.h>
#include <geometry_msgs/Twist.h>
#include <std_msgs/Empty.h>
#include <std_msgs/String.h>
#include <sstream>
#include <image_transport/image_transport.h>
#include <cv_bridge/cv_bridge.h>
#include <stdio.h>
#include <iostream>
#include <vector>
#include <sys/time.h>
#include <cmath>
#include "opencv2/core/core.hpp"
#include "opencv2/features2d/features2d.hpp"
#include "opencv2/nonfree/features2d.hpp"
#include "opencv2/nonfree/nonfree.hpp"
#include <ros/package.h>
#include "opencv2/calib3d/calib3d.hpp"
#include <geometry_msgs/Point.h>
#include <fstream>
#include <opencv2/video/tracking.hpp>
#include <opencv2/video/video.hpp>
using namespace cv;
using namespace std;
float ey,ez,ex;
float refz;
float xpast=0,ypast=0,zpast=0,xpastc=0,ypastc=0,zpastc=0;
//Values for Trackbar, Hue, Saturation Value
int iLowH=158;
int iHighH=179;
int iLowS=100;
int iHighS=255;
int iLowV=64;
int iHighV=255;
//Message initialization
geometry_msgs::Point point_msg;
std_msgs::Empty emp_msg;
geometry_msgs::Point punto;
geometry_msgs::Point puntoc;

//blob detection
SimpleBlobDetector::Params params;
std::vector<Point3f> col_3D(4);   
std::vector<Point2f> color_keypoints(4); 
float colorx,colory,colorz,fx,fy,fz;        
//Camera Matrix:
cv::Mat Matrix(3,3,CV_64F);
//Translation and rotation matrices
cv::Mat tvec;
cv::Mat rvec;
cv::Mat tvec_col;
cv::Mat rvec_col;
cv::Mat estimated;
cv::Mat estimatedc;
cv::Mat corrected;
//Distortion Vector
vector<double> distortion(5);
//Kalman Filter Initialization
int stateSize = 6;
int measSize = 3;
int contrSize = 0;
unsigned int type = CV_32F;
cv::KalmanFilter kf(stateSize, measSize, contrSize, type);
cv::Mat state(stateSize, 1, type);  // [x,y,z,v_x,v_y,v_z]
cv::Mat meas(measSize, 1, type);    // [z_x,z_y,z_z]

cv::KalmanFilter kfc(stateSize, measSize, 3, type);
cv::Mat statec(stateSize, 1, type);  // [x,y,z,v_x,v_y,v_z]
cv::Mat measc(measSize, 1, type);    // [z_x,z_y,z_z]
cv::Mat cn(3,1,type);
cv::Mat estimatedPast(stateSize,1,type);
cv::Mat estimatedPastc(stateSize,1,type);
int foundc=0;
int foundf=0;
//Simple Test Z
float zar,zab,zprom;
float estimatedx;
float estimatedy;
float estimatedz;
float estimatedvx;
float estimatedvy;
float estimatedvz;
geometry_msgs::Point posptav;
float estimatedcx;
float estimatedcy;
float estimatedcz;
float estimatedcvx;
float estimatedcvy;
float estimatedcvz;
cv::Mat EstimatedPose;
cv::Mat State;
Mat PnPStuff(Mat Obj3D,Mat color_key,Mat Matric,Mat distortionv,Mat rve,Mat tve,float xp,float yp,float zp)
{
	solvePnP(Obj3D,color_key,Matric,distortionv,rve,tve,false,CV_ITERATIVE);
	if(abs(tve.at<double>(0,0))>1500)
	{tve.at<double>(0,0)=tve.at<double>(0,0)/abs(tve.at<double>(0,0));}
	if(abs(tve.at<double>(1,0))>1500)
	{tve.at<double>(1,0)=tve.at<double>(1,0)/abs(tve.at<double>(1,0));}
	if(abs(tve.at<double>(2,0))>1500)
	{tve.at<double>(2,0)=tve.at<double>(2,0)/abs(tve.at<double>(2,0));}
	//Watch out big changes
	if(abs(tve.at<double>(0,0)-xp)>500)
	{tve.at<double>(0,0)=xp;}
	if(abs(tve.at<double>(1,0)-yp)>500)
	{tve.at<double>(1,0)=yp;}
	if(abs(tve.at<double>(2,0)-zp)>1)
	{tve.at<double>(2,0)=zp;}
	
}
geometry_msgs::Point Selection(geometry_msgs::Point Fea,geometry_msgs::Point Col,int F,int C)
{
	geometry_msgs::Point Preturn;
	if(F && C)
	{
		Preturn.x=(Fea.x+Col.x)/2.0;
		Preturn.y=(2*Fea.y+Col.y)/3.0;
		Preturn.z=(2*Fea.z+Col.z)/3.0;		
	}
	else if (F==1 && C==0)
	{
		Preturn.x=Fea.x;
		Preturn.y=Fea.y;
		Preturn.z=Fea.z;
	}
	else if (F==0 && C==1)
	{
		Preturn.x=Col.x;
		Preturn.y=Col.y;
		Preturn.z=Col.z;
	}
	return Preturn;
}
Mat Kalman(Mat Measure,KalmanFilter K)
{
							
	State=K.predict();	
	EstimatedPose=K.correct(Measure);
	return EstimatedPose;
}
Mat NaNCheck(Mat check,Mat past)
{
	if(check.at<float>(0)!=check.at<float>(0))
		{
			
		check.at<float>(0)=past.at<float>(0);
		check.at<float>(1)=past.at<float>(1);
		check.at<float>(2)=past.at<float>(2);
		check.at<float>(3)=past.at<float>(3);
		check.at<float>(4)=past.at<float>(4);
		check.at<float>(5)=past.at<float>(5);
		printf("hola");
		}
		past.at<float>(0)=check.at<float>(0);
		past.at<float>(1)=check.at<float>(1);
		past.at<float>(2)=check.at<float>(2);
		past.at<float>(3)=check.at<float>(3);
		past.at<float>(4)=check.at<float>(4);
		past.at<float>(5)=check.at<float>(5);
	return check;
}
void imageCallback(const sensor_msgs::ImageConstPtr& msg)
	{
		ros::Rate loop_rate(50);
		ofstream myfile("/home/edrone/VelocidadesEstimadas.txt",ios_base::app);
		int count=0;
		//Node initialization
		Point pt;
		ros::NodeHandle neu;
		ros::Publisher pub_empty_land;
		ros::Publisher pub_point=neu.advertise<geometry_msgs::Point>("color_position",1);
		pub_empty_land = neu.advertise<std_msgs::Empty>("/ardrone/land", 1); /* Message queue length is just 1 */
	
		//Communicating between ROS an OpenCV
		cv_bridge::CvImagePtr cv_ptr; 
		cv::Mat img_thr;
		std::vector<Point3f> col_3D(4);   
		std::vector<Point2f> color_keypoints(4);  
		  try
		  {
				//Color Tracking Initialization
				std::string image = ros::package::getPath("stream") + "/src/gbox.jpg";
				cv_ptr=cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
				cv::Mat img2;
				cv::Mat color;
				cv::Mat gauss;
				cv::Mat blobs;
				color=cv_ptr->image;
				cv::GaussianBlur( cv_ptr->image, gauss, Size( 3, 3 ), 0, 0 );
				cv::cvtColor(gauss,gauss,CV_BGR2HSV); 
				cvCreateTrackbar("LowH", "blob", &iLowH, 179); 
				cvCreateTrackbar("HighH", "blob", &iHighH, 179); 
				cvCreateTrackbar("LowS", "blob", &iLowS, 255); 
				cvCreateTrackbar("HighS", "blob", &iHighS, 255); 
				cvCreateTrackbar("LowV", "blob", &iLowV, 255); 
				cvCreateTrackbar("HighV", "blob", &iHighV, 255);
				cv::inRange(gauss, cv::Scalar(iLowH,iLowS,iLowV), cv::Scalar(iHighH,iHighS,iHighV), gauss); 
				imshow("Color", gauss);
				//Color reference
				col_3D[0] = Point3f(-0.115,-0.08,0); 
				col_3D[1] = Point3f(0.115,-0.08,0);
				col_3D[2] = Point3f(-0.24,0.245,0); 
				col_3D[3] = Point3f(0.24,0.245,0);
				//Thresholding
				cv::cvtColor(cv_ptr->image,img2,CV_BGR2GRAY);
				Mat img1 = imread(image, CV_LOAD_IMAGE_GRAYSCALE );
				geometry_msgs::Point posptc;
				if( img1.empty() ) 
				{
			 		printf("Error occured, image not read correctly \n");
				}
				//Blob detection
				vector<KeyPoint> keyPointsBlob;
				SimpleBlobDetector blobDetector( params );
				blobDetector.detect( gauss, keyPointsBlob );
				if(keyPointsBlob.size()==4)//Just work if find 4 blobs
				{
					drawKeypoints(gauss,keyPointsBlob,blobs,Scalar::all(-1),DrawMatchesFlags::DEFAULT);
					imshow("blob", blobs );
					for(int a=0;a<keyPointsBlob.size();a=a+1)
					{
						color_keypoints[a]=keyPointsBlob[a].pt;
					}

					//PnP color Stuff
					solvePnP(Mat(col_3D),Mat(color_keypoints),Matrix,distortion,rvec_col,tvec_col,false,CV_ITERATIVE);

					colorx=tvec_col.at<double>(0,0);
					colory=tvec_col.at<double>(1,0);
					colorz=tvec_col.at<double>(2,0);
					
					if(abs(tvec_col.at<double>(0,0))>1500)
					{tvec_col.at<double>(0,0)=tvec_col.at<double>(0,0)/abs(tvec_col.at<double>(0,0));}
					if(abs(tvec_col.at<double>(1,0))>1500)
					{tvec_col.at<double>(1,0)=tvec_col.at<double>(1,0)/abs(tvec_col.at<double>(1,0));}
					if(abs(tvec_col.at<double>(2,0))>1500)
					{tvec_col.at<double>(2,0)=tvec_col.at<double>(2,0)/abs(tvec_col.at<double>(2,0));}
					//Watch out big changes
					if(abs(tvec_col.at<double>(0,0)-xpastc)>500)
					{tvec_col.at<double>(0,0)=xpastc;}
					if(abs(tvec_col.at<double>(1,0)-ypastc)>500)
					{tvec_col.at<double>(1,0)=ypastc;}
					if(abs(tvec_col.at<double>(2,0)-zpastc)>1)
					{tvec_col.at<double>(2,0)=zpastc;}
					
					



					puntoc.x=tvec_col.at<double>(0,0);
					puntoc.y=tvec_col.at<double>(1,0);
					puntoc.z=tvec_col.at<double>(2,0);
					
					//imshow("view", img_matches );
					xpastc=tvec_col.at<double>(0,0);
					ypastc=tvec_col.at<double>(1,0);
					zpastc=tvec_col.at<double>(2,0);
					//Straight to Kalman
					measc.at<float>(0) = puntoc.x;
					measc.at<float>(1) = puntoc.y;
					measc.at<float>(2) = puntoc.z;

					foundc=1;

				}
				else
				{										
					puntoc.x=xpastc;
					puntoc.y=ypastc;
					puntoc.z=zpastc;
					measc.at<float>(0) = puntoc.x;
					measc.at<float>(1) = puntoc.y;
					measc.at<float>(2) = puntoc.z;
					foundc=0;
					printf("holi");
					imshow("blob", gauss );
				}
				
				//Detector, and extractor initializing
				//Detector, and extractor initializing
				//IMPORTAAAAAAAAAANT, REMEMBER TO CHECK SURF AND SIFT, 'CAUSE SCALE INVARIANCE PROBLEM :-(
				//UUUUSMJSJIASLJADSJLDAJILDAJILDAJILDALJ?????ยก!!!!!!!!!!!!!!!!!
				//!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
				OrbFeatureDetector detector;
			    	vector<KeyPoint> keypoints1, keypoints2,objk,scenek;
				detector.detect(img1, keypoints1);
				    // computing descriptors
				OrbDescriptorExtractor extractor;
				Mat descriptors1, descriptors2;
				extractor.compute(img1, keypoints1, descriptors1);
				//Matching
				BFMatcher matcher(NORM_HAMMING,false);
				vector< vector< DMatch > > matches;
				vector<DMatch> good_matches;
				

				//Vector Initializing		
				Point center;
				DMatch Forward,Backward;
				std::vector<Point2f> obj;
				std::vector<Point2f> scene;
				float posY=0.0;
				float posZ=0.0;
				
		
				detector.detect(img2, keypoints2);
			    	// computing descriptors
			    	extractor.compute(img2, keypoints2, descriptors2);
				

				matcher.knnMatch(descriptors2, descriptors1, matches, 2);
				//Good Matches Selection
				for (int i = 0; i < matches.size(); ++i)
				{
				    const float ratio = 0.7; // As in Lowe's paper; can be tuned
				    if (matches[i][0].distance < ratio * matches[i][1].distance)
				    {
					good_matches.push_back(matches[i][0]);
				    }
				}
				for( int i = 0; i < good_matches.size(); i++ )
				{
					  //-- Get the keypoints from the good matches
					scene.push_back( keypoints2[ good_matches[i].queryIdx ].pt );
					obj.push_back( keypoints1[ good_matches[i].trainIdx ].pt );
				
					scenek.push_back( keypoints2[ good_matches[i].queryIdx ] );
					objk.push_back( keypoints1[ good_matches[i].trainIdx ] );

				}
				geometry_msgs::Point pospt;
				
				if(good_matches.size()>9)
				{
					Mat H = findHomography( obj, scene, CV_RANSAC );
				
					//-- Get the corners from the image_1 ( the object to be "detected" )
					std::vector<Point2f> obj_corners(5);
					std::vector<Point3f> obj_3D(5);
					obj_corners[0] = cvPoint(0,0); 
					obj_corners[1] = cvPoint( img1.cols, 0 );
					obj_corners[2] = cvPoint( img1.cols, img1.rows ); 
					obj_corners[3] = cvPoint( 0, img1.rows );
					obj_corners[4] = cvPoint( img1.cols/2, img1.rows/2 );
					obj_3D[0] = Point3f(-0.26,0.26,0); 
					obj_3D[1] = Point3f( 0.26, 0.26,0 );
					obj_3D[2] = Point3f( 0.26, -0.26,0 ); 
					obj_3D[3] = Point3f( 0, 0.26 ,0);
					obj_3D[4] = Point3f( 0.0, 0.0 ,0);
					std::vector<Point2f> scene_corners(5);
				
					perspectiveTransform( obj_corners, scene_corners, H);

	  //-- Draw lines between the corners (the mapped object in the scene - image_2 )
					Mat img_matches;
					cv::Mat img_keypoints_2;

			  		  drawMatches(  img2, keypoints2,img1, keypoints1,good_matches, img_matches, Scalar::all(-1), Scalar::all(-1),vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS );
		
		
					good_matches.clear();
					obj.clear();
					scene.clear();
					objk.clear();
					scenek.clear();

					line( img_matches, scene_corners[0], scene_corners[1] , Scalar(255, 255, 0), 4 );
					  line( img_matches, scene_corners[1] , scene_corners[2] , Scalar( 0, 255, 0), 4 );
					  line( img_matches, scene_corners[2] , scene_corners[3] , Scalar( 255, 255, 0), 4 );
					  line( img_matches, scene_corners[3] , scene_corners[0] , Scalar( 0, 255, 0), 4);
					circle( img_matches, scene_corners[4], 32.0, Scalar( 0, 0, 255 ), 4, 8 );
					/*Test for simplier Z*/
					zar=scene_corners[0].x-scene_corners[1].x;
					zab=scene_corners[2].x-scene_corners[3].x;
					zprom=abs(zar+zab)/2.0;
					//PNP stuff
					solvePnP(Mat(obj_3D),Mat(scene_corners),Matrix,distortion,rvec,tvec,false,CV_ITERATIVE);
					//Watch out big values
					if(abs(tvec.at<double>(0,0))>1500)
					{tvec.at<double>(0,0)=tvec.at<double>(0,0)/abs(tvec.at<double>(0,0));}
					if(abs(tvec.at<double>(1,0))>1500)
					{tvec.at<double>(1,0)=tvec.at<double>(1,0)/abs(tvec.at<double>(1,0));}
					if(abs(tvec.at<double>(2,0))>1500)
					{tvec.at<double>(2,0)=tvec.at<double>(2,0)/abs(tvec.at<double>(2,0));}
					//Watch out big changes
					if(abs(tvec.at<double>(0,0)-xpast)>500)
					{tvec.at<double>(0,0)=xpast;}
					if(abs(tvec.at<double>(1,0)-ypast)>500)
					{tvec.at<double>(1,0)=ypast;}
					if(abs(tvec.at<double>(2,0)-zpast)>500)
					{tvec.at<double>(2,0)=zpast;}
					
					



					punto.x=tvec.at<double>(0,0);
					punto.y=tvec.at<double>(1,0);
					punto.z=tvec.at<double>(2,0);

					fx=tvec.at<double>(0,0);
					fy=tvec.at<double>(1,0);
					fz=tvec.at<double>(2,0);
					//Straight to Kalman
					meas.at<float>(0) = punto.x;
					meas.at<float>(1) = punto.y;
					meas.at<float>(2) = punto.z;
					imshow("view", img_matches );
					xpast=tvec.at<double>(0,0);
					ypast=tvec.at<double>(1,0);
					zpast=tvec.at<double>(2,0);
					foundf=1;
				}
				else
				{
					punto.x=xpast;
					punto.y=ypast;
					punto.z=zpast;
					meas.at<float>(0) = punto.x;
					meas.at<float>(1) = punto.y;
					meas.at<float>(2) = punto.z;
					foundf=0;
					printf("hole");
					
				}

				


				

				//Kalman Prediction and Correction	
				estimatedc=Kalman(meas,kfc);
				estimated=Kalman(meas,kf);
				//Check for Nan
				estimated=NaNCheck(estimated,estimatedPast);
				estimatedc=NaNCheck(estimatedc,estimatedPastc);
		

				//Save Kalman for ROS message				
				pospt.x=estimated.at<float>(0);
				pospt.y=estimated.at<float>(1);
				pospt.z=estimated.at<float>(2);

				posptc.x=estimatedc.at<float>(0);
				posptc.y=estimatedc.at<float>(1);
				posptc.z=estimatedc.at<float>(2);

				/*posptav.x=(pospt.x+posptc.x)/2;
				posptav.y=(pospt.y+posptc.y)/2;
				posptav.z=(pospt.z+posptc.z)/2;*/
				posptav=Selection(pospt,posptc,foundf,foundc);
				printf("[%f	%f	%f	%f] \n",pospt.x,posptc.x,pospt.z,posptc.z);
				//myfile <<posptav.x<<"	"<<posptc.x<<"	"<<pospt.x<<"	"<<posptav.y<<"	"<<posptc.y<<"	"<<pospt.y<<"	"<<posptav.z<<"	"<<posptc.z<<"	"<<pospt.z<<"\n";
				myfile <<estimatedc.at<float>(3)<<"	"<<estimatedc.at<float>(4)<<"	"<<estimatedc.at<float>(5)<<"\n";				
			pub_point.publish(posptav);
			cv::waitKey(15);
			ros::spinOnce();
			
		  }

		  catch (cv_bridge::Exception& e)
		  {
		    ROS_ERROR("Could not convert from '%s' to 'bgr8'.", msg->encoding.c_str());
		  }
	
	
	}

int main(int argc, char **argv)
{
	//Initializing ROS
	ros::init(argc, argv, "tracker");
	ros::NodeHandle nh;
	ros::Rate loop_rate(50);	
	cv::namedWindow("view");
	cv::namedWindow("blob");
	cv::namedWindow("Color");
	cv::startWindowThread();
	//Blob detection initialization
	params.minThreshold = 40;
        params.maxThreshold = 60;
        params.thresholdStep = 5;
	params.minCircularity=0.5;
        params.minArea = 100;
        params.minConvexity = 0.3;
        params.minInertiaRatio = 0.01;
	
        params.maxArea = 8000;
        params.maxConvexity = 10;
	params.filterByInertia = false;
  	params.filterByConvexity = false;
  	params.filterByArea = true;
        params.filterByColor = false;
        params.filterByCircularity = false;
	params.blobColor = 220;	
	//Initializing camera matrix
	Matrix.at<double>(0,0)=560.21;
	Matrix.at<double>(0,1)=0.0;
	Matrix.at<double>(0,2)=336.8;
	Matrix.at<double>(1,0)=0.0;
	Matrix.at<double>(1,1)=558.91;
	Matrix.at<double>(1,2)=172.37;
	Matrix.at<double>(2,0)=0.0;
	Matrix.at<double>(2,1)=0.0;
	Matrix.at<double>(2,2)=1.0;
	//Initializing distortion vector
	distortion[0]=-0.521;
	distortion[1]=0.278;
	distortion[2]=0.0009;
	distortion[3]=0.0008;
	distortion[4]=0;


	float dt=0.0647;//Dont know it yet

	//Feature Kalman Filter
	//Transition Matrix A
	cv::setIdentity(kf.transitionMatrix);
	kf.transitionMatrix.at<float>(0,3)=dt;
	kf.transitionMatrix.at<float>(1,4)=dt;
	kf.transitionMatrix.at<float>(2,5)=dt;
	//Measurement Matrix H
	kf.measurementMatrix = cv::Mat::zeros(measSize, stateSize, type);
	kf.measurementMatrix.at<float>(0,0) = 1.0f;
	kf.measurementMatrix.at<float>(1,1) = 1.0f;
	kf.measurementMatrix.at<float>(2,2) = 1.0f;
	//Noise Covariance Matrix Q
	kf.processNoiseCov.at<float>(0,0) = 1e-5;
	kf.processNoiseCov.at<float>(1,1) = 1e-5;
	kf.processNoiseCov.at<float>(2,2) = 1e-5;
	kf.processNoiseCov.at<float>(3,3) = 1e-5;
	kf.processNoiseCov.at<float>(4,4) = 1e-5;
	kf.processNoiseCov.at<float>(5,5) = 1e-5;
	kf.measurementNoiseCov.at<float>(0,0) = 1e-3;
	kf.measurementNoiseCov.at<float>(1,1) = 1e-3;
	kf.measurementNoiseCov.at<float>(2,2) = 1e-1;
	
	cv::setIdentity(kf.errorCovPost, cv::Scalar::all(0.1));

	//Color Kalman Filter
	//Transition Matrix A
	kfc.transitionMatrix = cv::Mat::zeros(stateSize, stateSize, type);
	kfc.transitionMatrix.at<float>(0,3)=40;
	kfc.transitionMatrix.at<float>(1,4)=25;
	kfc.transitionMatrix.at<float>(2,5)=20;
	kfc.transitionMatrix.at<float>(3,3)=-10;
	kfc.transitionMatrix.at<float>(4,4)=-10;
	kfc.transitionMatrix.at<float>(5,5)=-10;
	//control matrix
	kfc.controlMatrix=cv::Mat::zeros(7,3,type);
	kfc.controlMatrix.at<float>(3,0)=6;
	kfc.controlMatrix.at<float>(4,1)=4.5;
	kfc.controlMatrix.at<float>(5,2)=100;
	//Measurement Matrix H
	kfc.measurementMatrix = cv::Mat::zeros(measSize, stateSize, type);
	kfc.measurementMatrix.at<float>(0,0) = 1.0f;
	kfc.measurementMatrix.at<float>(1,1) = 1.0f;
	kfc.measurementMatrix.at<float>(2,2) = 1.0f;
	//Noise Covariance Matrix Q
	kfc.processNoiseCov.at<float>(0,0) = 1e-5;
	kfc.processNoiseCov.at<float>(1,1) = 1e-5;
	kfc.processNoiseCov.at<float>(2,2) = 1e-5;
	kfc.processNoiseCov.at<float>(3,3) = 1e-4;
	kfc.processNoiseCov.at<float>(4,4) = 1e-4;
	kfc.processNoiseCov.at<float>(5,5) = 1e-4;
	kfc.measurementNoiseCov.at<float>(0,0) = 1e-3;
	kfc.measurementNoiseCov.at<float>(1,1) = 1e-3;
	kfc.measurementNoiseCov.at<float>(2,2) = 1e-1;
	
	cv::setIdentity(kfc.errorCovPost, cv::Scalar::all(0.1));

	//Trouble with estimated
	estimatedPast.at<float>(0)=0.0;
	estimatedPast.at<float>(1)=0.0;
	estimatedPast.at<float>(2)=0.0;
	estimatedPast.at<float>(3)=0.0;
	estimatedPast.at<float>(4)=0.0;
	estimatedPast.at<float>(5)=0.0;
	estimatedPastc.at<float>(0)=0.0;
	estimatedPastc.at<float>(1)=0.0;
	estimatedPastc.at<float>(2)=0.0;
	estimatedPastc.at<float>(3)=0.0;
	estimatedPastc.at<float>(4)=0.0;
	estimatedPastc.at<float>(5)=0.0;
	//Subscribing to ardrone camera node
	image_transport::ImageTransport it(nh);
	image_transport::Subscriber sub = it.subscribe("/ardrone/image_raw", 1, imageCallback);
	ros::spin();
	cv::destroyWindow("view");
	cv::destroyWindow("blob");
	cv::destroyWindow("Color");
}


