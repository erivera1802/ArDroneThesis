#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <sensor_msgs/image_encodings.h>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <cv_bridge/cv_bridge.h>
#include <geometry_msgs/Twist.h>
#include <std_msgs/Empty.h>
#include <std_msgs/String.h>
#include <sstream>
#include <image_transport/image_transport.h>
#include <cv_bridge/cv_bridge.h>
#include <stdio.h>
#include <iostream>
#include <vector>
#include <sys/time.h>
#include <cmath>
#include "opencv2/core/core.hpp"
#include "opencv2/features2d/features2d.hpp"
#include "opencv2/nonfree/features2d.hpp"
#include "opencv2/nonfree/nonfree.hpp"
#include <ros/package.h>
#include "opencv2/calib3d/calib3d.hpp"
#include <geometry_msgs/Point.h>
#include <fstream>
#include <opencv2/video/tracking.hpp>
#include <opencv2/video/video.hpp>
using namespace cv;
using namespace std;
float ey,ez,ex;
float refz;
float xpast=0,ypast=0,zpast=0;
//float PosX,PosY,PosZ;
geometry_msgs::Point point_msg;
std_msgs::Empty emp_msg;

//Camera Matrix:
cv::Mat Matrix(3,3,CV_64F);
//Translation and rotation matrices
cv::Mat tvec;
cv::Mat rvec;
//Distortion Vector
vector<double> distortion(5);


	void imageCallback(const sensor_msgs::ImageConstPtr& msg)
	{
		ros::Rate loop_rate(50);
		ofstream myfile("/home/edrone/pos.txt",ios_base::app);
		int count=0;
		
		Point pt;
		ros::NodeHandle neu;
		ros::Publisher pub_empty_land;
		ros::Publisher pub_point=neu.advertise<geometry_msgs::Point>("color_position",1000);
		pub_empty_land = neu.advertise<std_msgs::Empty>("/ardrone/land", 1); /* Message queue length is just 1 */
	
		//Communicating between ROS an OpenCV
		cv_bridge::CvImagePtr cv_ptr; 
		cv::Mat img_thr;

		  try
		  {


				std::string image = ros::package::getPath("stream") + "/src/paint.jpg";
				cv_ptr=cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
				cv::Mat img2;
				cv::Mat color;
				color=cv_ptr->image;
				//Thresholding
				cv::cvtColor(cv_ptr->image,img2,CV_BGR2GRAY);
				Mat img1 = imread(image, CV_LOAD_IMAGE_GRAYSCALE );

				if( img1.empty() ) 
				{
			 		printf("Error occured, image not read correctly \n");
				}

				//Detector, and extractor initializing
				OrbFeatureDetector detector;
			    	vector<KeyPoint> keypoints1, keypoints2,objk,scenek;
				detector.detect(img1, keypoints1);
				    // computing descriptors
				OrbDescriptorExtractor extractor;
				Mat descriptors1, descriptors2;
				extractor.compute(img1, keypoints1, descriptors1);
				//Matching
				BFMatcher matcher(NORM_HAMMING,false);
				vector< vector< DMatch > > matches;
				vector<DMatch> good_matches;
				

				//Vector Initializing		
				Point center;
				DMatch Forward,Backward;
				std::vector<Point2f> obj;
				std::vector<Point2f> scene;
				float posY=0.0;
				float posZ=0.0;
				
		
				detector.detect(img2, keypoints2);
			    	// computing descriptors
			    	extractor.compute(img2, keypoints2, descriptors2);
				

				matcher.knnMatch(descriptors2, descriptors1, matches, 2);
				//Good Matches Selection
				for (int i = 0; i < matches.size(); ++i)
				{
				    const float ratio = 0.7; // As in Lowe's paper; can be tuned
				    if (matches[i][0].distance < ratio * matches[i][1].distance)
				    {
					good_matches.push_back(matches[i][0]);
				    }
				}
				for( int i = 0; i < good_matches.size(); i++ )
				{
					  //-- Get the keypoints from the good matches
					scene.push_back( keypoints2[ good_matches[i].queryIdx ].pt );
					obj.push_back( keypoints1[ good_matches[i].trainIdx ].pt );
				
					scenek.push_back( keypoints2[ good_matches[i].queryIdx ] );
					objk.push_back( keypoints1[ good_matches[i].trainIdx ] );

				}
				geometry_msgs::Point pospt;
				if(good_matches.size()>3)
				{
					Mat H = findHomography( obj, scene, CV_RANSAC );
				
					//-- Get the corners from the image_1 ( the object to be "detected" )
					std::vector<Point2f> obj_corners(5);
					std::vector<Point3f> obj_3D(5);
					obj_corners[0] = cvPoint(0,0); 
					obj_corners[1] = cvPoint( img1.cols, 0 );
					obj_corners[2] = cvPoint( img1.cols, img1.rows ); 
					obj_corners[3] = cvPoint( 0, img1.rows );
					obj_corners[4] = cvPoint( img1.cols/2, img1.rows/2 );
					obj_3D[0] = Point3f(0,0,0); 
					obj_3D[1] = Point3f( img1.cols, 0,0 );
					obj_3D[2] = Point3f( img1.cols, img1.rows,0 ); 
					obj_3D[3] = Point3f( 0, img1.rows ,0);
					obj_3D[4] = Point3f( img1.cols/2, img1.rows/2 ,0);
					std::vector<Point2f> scene_corners(5);
				
					perspectiveTransform( obj_corners, scene_corners, H);

	  //-- Draw lines between the corners (the mapped object in the scene - image_2 )
					  

			
						
						//Posx, Posy
						/*pospt.x=scene_corners[4].x;
						pospt.y=scene_corners[4].y;
						
						//PosZ
						refz=abs(obj_corners[1].x-obj_corners[0].x)*abs(obj_corners[3].y-obj_corners[0].y)*0.5;
						pospt.z=(abs(scene_corners[1].x-scene_corners[0].x)*abs(scene_corners[3].y-scene_corners[0].y)/refz)-1;
						if(abs(pospt.z)>1)
							{pospt.z=pospt.z/abs(pospt.z);}					
						printf("[%f,%f,%f] \n",pospt.x,pospt.y,pospt.z);*/
						Mat img_matches;
						
						cv::Mat img_keypoints_2;

			  		  drawMatches(  img2, keypoints2,img1, keypoints1,good_matches, img_matches, Scalar::all(-1), Scalar::all(-1),vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS );
		
		
					good_matches.clear();
					obj.clear();
					scene.clear();
					objk.clear();
					scenek.clear();

					line( img_matches, scene_corners[0], scene_corners[1] , Scalar(0, 255, 0), 4 );
					  line( img_matches, scene_corners[1] , scene_corners[2] , Scalar( 0, 255, 0), 4 );
					  line( img_matches, scene_corners[2] , scene_corners[3] , Scalar( 0, 255, 0), 4 );
					  line( img_matches, scene_corners[3] , scene_corners[0] , Scalar( 0, 255, 0), 4);
					circle( img_matches, scene_corners[4], 32.0, Scalar( 0, 0, 255 ), 4, 8 );
					
					//PNP stuff
					solvePnP(Mat(obj_3D),Mat(scene_corners),Matrix,distortion,rvec,tvec,false,CV_ITERATIVE);
					
					
					//cv::Mat R;
					//cv::Rodrigues(rvec, R); // R is 3x3

					//R = R.t();  // rotation of inverse
					//tvec = -R * tvec; // translation of inverse
					printf("[%f,%f,%f] \n",tvec.at<double>(0,0),tvec.at<double>(1,0),tvec.at<double>(2,0));
					//Watch out big values
					if(abs(tvec.at<double>(0,0))>1500)
					{tvec.at<double>(0,0)=tvec.at<double>(0,0)/abs(tvec.at<double>(0,0));}
					if(abs(tvec.at<double>(1,0))>1500)
					{tvec.at<double>(1,0)=tvec.at<double>(1,0)/abs(tvec.at<double>(1,0));}
					if(abs(tvec.at<double>(2,0))>1500)
					{tvec.at<double>(2,0)=tvec.at<double>(2,0)/abs(tvec.at<double>(2,0));}
					//Watch out big changes
					if(abs(tvec.at<double>(0,0)-xpast)>500)
					{tvec.at<double>(0,0)=xpast;}
					if(abs(tvec.at<double>(1,0)-ypast)>500)
					{tvec.at<double>(1,0)=ypast;}
					if(abs(tvec.at<double>(2,0)-zpast)>500)
					{tvec.at<double>(2,0)=zpast;}
					
					



					pospt.x=tvec.at<double>(0,0);
					pospt.y=tvec.at<double>(1,0);
					pospt.z=tvec.at<double>(2,0);
					myfile << pospt.x<<"   "<< pospt.y<<"   "<< pospt.z<<"\n";
						pub_point.publish(pospt);
					imshow("view", img_matches );
					xpast=tvec.at<double>(0,0);
					ypast=tvec.at<double>(1,0);
					zpast=tvec.at<double>(2,0);
				}
				else
				{
					pospt.x=0.0;
					pospt.y=0.0;
					pospt.z=0.0;
				}

			cv::waitKey(15);
			ros::spinOnce();
			
		  }

		  catch (cv_bridge::Exception& e)
		  {
		    ROS_ERROR("Could not convert from '%s' to 'bgr8'.", msg->encoding.c_str());
		  }
	
	
	}

int main(int argc, char **argv)
{
	//Initializing ROS
	ros::init(argc, argv, "tracker");
	ros::NodeHandle nh;
	ros::Rate loop_rate(50);	
	cv::namedWindow("view");
	cv::startWindowThread();
	twist_msg.linear.x=0.0;
	twist_msg.linear.y=0.0;	
	twist_msg.angular.z=0.0;
	twist_msg.angular.y=0.0;
		
	//Initializing camera matrix
	Matrix.at<double>(0,0)=560.21;
	Matrix.at<double>(0,1)=0.0;
	Matrix.at<double>(0,2)=336.8;
	Matrix.at<double>(1,0)=0.0;
	Matrix.at<double>(1,1)=558.91;
	Matrix.at<double>(1,2)=172.37;
	Matrix.at<double>(2,0)=0.0;
	Matrix.at<double>(2,1)=0.0;
	Matrix.at<double>(2,2)=1.0;
	//Initializing distortion vector
	distortion[0]=-0.521;
	distortion[1]=0.278;
	distortion[2]=0.0009;
	distortion[3]=0.0008;
	distortion[4]=0;

	//Subscribing to ardrone camera node
	image_transport::ImageTransport it(nh);
	image_transport::Subscriber sub = it.subscribe("/ardrone/image_raw", 1, imageCallback);
	ros::spin();
	cv::destroyWindow("view");
}




